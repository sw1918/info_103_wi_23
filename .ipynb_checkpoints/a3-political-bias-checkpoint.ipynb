{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fb9e2fa-5f32-4ddc-bf9c-5256d8e5076a",
   "metadata": {},
   "source": [
    "# A3: Political Bias\n",
    "In this assignment, you will be trying to calcualate the average political bias and reliability of posts in a subreddit.\n",
    "\n",
    "The code you are starting with here already does a search on a subreddit and finds the reliability and political bias of url web addresses posted to subreddits. You will need to add loop variables to calculate these averages (see chapter 8 practice and demos).\n",
    "\n",
    "After you get the averages to work, you wll then try your code on other subreddits, and then you will answer some reflection questions.\n",
    "\n",
    "First, we'll do our normal Reddit Praw login steps (though we'll not use fake-praw for this assignment, only real Reddit)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fef2034-dcde-40b6-9329-b446a0e931f5",
   "metadata": {},
   "source": [
    "## Reddit PrawSetup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9b9f36-4fe8-4852-adf5-1135f70c7e41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b7be23-dfc0-43e6-a049-acd686dc3a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run reddit_keys.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078b3e41-1c0e-4fad-bc4d-9c1fd0c28a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the praw code your reddit account info so\n",
    "# it can perform reddit actions\n",
    "reddit = praw.Reddit(\n",
    "    username=username, password=password,\n",
    "    client_id=client_id, client_secret=client_secret,\n",
    "    user_agent=\"a custom python script for user /\" + str(username)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2dbd35-52bf-4b5b-943d-3485ef7bad6a",
   "metadata": {},
   "source": [
    "## Load Bias and Reliability Info\n",
    "The code to load the bias and reliability info is in another file: `a3-supporting_code.ipynb`. You can look at that file if you are interested, but you are not required to.\n",
    "\n",
    "The part you should know is that the measures of website bias and reliability are based on the [Media Bias Chart](https://adfontesmedia.com/static-mbc) (old version 9.0). We took their ratings of reliability and bias and simplified them into a scale with bias ranging from -4 (extremely liberal) to +4 (extremely conservative), and reliability from +2 (fact reporting) to -4 (fabricated or inaccurate). We then chose a few of the more common websites to let us look up info.\n",
    "![Media bias chart with grid, showing the range labels](./imgs/bias_chart_divisions.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789def50-4d8a-493b-a8fd-e4c19f677011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can look in this file if you want to see more\n",
    "# about how the file information is loaded\n",
    "%run a3-supporting_code.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046f4b2c-16af-4e92-bf60-f344b7116fa5",
   "metadata": {},
   "source": [
    "## Get a list of results from a subreddit\n",
    "We will now get a list of results from reddit. To start with we get 20 posts from the \"news\" subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf92204c-fa40-45ad-b0c9-0c63bf029093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look up the subreddit \"news\", then find the \"hot\" list, getting up to 100 submission\n",
    "submissions = reddit.subreddit(\"news\").hot(limit=20)\n",
    "\n",
    "# Turn the submission results into a Python List\n",
    "submissions_list = list(submissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72c2e28-ce05-4414-a6c7-d6431cc2744b",
   "metadata": {},
   "source": [
    "## TODO: Modify the code below (Run Search)\n",
    "The code below loops through each reddit submission, and if the submission was a website url, the program checks to see if we have reliability/bias info on the site. If we have that info we calculate the bias and reliability and display it.\n",
    "\n",
    "__Your job__ is to add loop variables to the code to calculate the number of urls we had info for (`number_matched_urls`) and then the total bias and total reliability for those urls. Then you can use that at the end to calculate the average bias and average reliability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e03b95-f18f-47d9-855a-b8a824d8a57c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### TODO: make three loop variables here: ####\n",
    "#   number_matched_urls\n",
    "#   total_url_bias\n",
    "#   total_url_reliability\n",
    "\n",
    "\n",
    "# go through all the tweets\n",
    "for submission in submissions_list:\n",
    "    \n",
    "    print(submission.url)\n",
    "\n",
    "    # if the submission was a website url link, then we'll\n",
    "    if submission.url:\n",
    "        \n",
    "        # try to find the source website in our dataset\n",
    "        matching_site = find_matching_site(submission.url)\n",
    "\n",
    "        # if we found the matching site, then we have info for it\n",
    "        if(matching_site):\n",
    "            \n",
    "            # look up the bias and reliability for the site the url is from\n",
    "            url_bias = media_bias_lookup[matching_site]\n",
    "            url_reliability = media_reliability_lookup[matching_site]\n",
    "\n",
    "            #### TODO: Update the three loop variables here #### \n",
    "\n",
    "            print(\"  bias: \" + str(url_bias))\n",
    "            print(\"  reliability: \" + str(url_reliability))\n",
    "        else:\n",
    "            # We didn't have info on this site\n",
    "            print(\"**did not recognize site!\")\n",
    "\n",
    "    print()\n",
    "        \n",
    "\n",
    "####  TODO: Use the loop variables to calculate the total number of urls #### \n",
    "#  we cold measure and then the average bias and reliability for those\n",
    "# Then display them with the print statements below\n",
    "\n",
    "print(\"--------------------------------------\")\n",
    "print(\"Total number of urls we could measure: \")\n",
    "print(\"Average bias: \")\n",
    "print(\"Average reliability: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be133008-425f-4f8d-bdd1-70ad89b80ed9",
   "metadata": {},
   "source": [
    "## Reflection tasks\n",
    "\n",
    "Once you get the code above working and finding an average bias and reliability, modify the search to try at least three more subreddits (and get more posts at a time, like 100). Open up the subreddit separately and look at your results, then answer the questions below.\n",
    "\n",
    "Note: For searches, you can search for different subreddits that might have different views and post links to news articles, like: \"news\", \"science\", \"politics\", \"liberal\", \"conservative\", \"tech\", \"BlackLivesMatter\",  etc.\n",
    "\n",
    "1. What additional searches did you run (at least 3)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c473e9-5b16-4edd-9777-8bbff17a1c95",
   "metadata": {},
   "source": [
    "TODO: Answer the question here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd86be7b-ecb5-4c96-b62a-2daa34e613f2",
   "metadata": {},
   "source": [
    "2. When doing those searches, what were your observations about the calculations of media bias and reliability? (For example: were there a lot of urls that you didn't measure? Do you feel like the final calculated bias and reliability match the search results?). Answer with at least 3 sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcffa15-14b2-4e6c-9028-7720d9c4b348",
   "metadata": {},
   "source": [
    "TODO: Answer the question here with at least 3 sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0806f464-3fa7-4df4-94ea-263604df64b9",
   "metadata": {},
   "source": [
    "3. If you could redesign the Media Bias Chart, what would you want to do (e.g., add some other dimension besides just bias/responsibility, change how it is evaluated, add more news sources, consider different countries)? Answer with at least 3 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb476ec9-4306-4169-8afb-8f9141f550e3",
   "metadata": {},
   "source": [
    "TODO: Answer the question here with at least 3 sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d2d1c9-68d8-420c-8181-2bca8f974f43",
   "metadata": {},
   "source": [
    "4. What might a social media companies or advertizers (including political campaigns) want to do with information on a users' political views and susceptibility to consipracy theories? Answer with at least 3 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaffa22-0536-4a79-a5f4-f70f9662e43e",
   "metadata": {},
   "source": [
    "TODO: Answer the question here with at least 3 sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db14d6f-0dad-42ec-a8f8-3959ec040e72",
   "metadata": {},
   "source": [
    "5. Choose two ethics frameworks and use the frameworks to consider the different uses of the media bias and reliability information. Answer with at least 6 sentences total (e.g., 3 per framework)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a34598-ec1d-4dd7-94ee-469170bfd176",
   "metadata": {},
   "source": [
    "TODO: Answer the question here with at least 6 sentences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
